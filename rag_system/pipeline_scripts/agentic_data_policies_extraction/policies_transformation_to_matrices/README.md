# Pipeline de Transformation des Politiques en Matrices

Ce projet fait partie du syst√®me RAG (Retrieval-Augmented Generation) pour l'extraction et l'analyse de politiques de sobri√©t√©. Il transforme les donn√©es extraites de conclusions d'articles scientifiques en matrices structur√©es et les enrichit avec des taxonomies th√©matiques et des analyses de clustering s√©mantique.

## üéØ Objectif

Transformer les donn√©es JSON extraites de politiques de sobri√©t√© en format tabulaire (CSV), associer chaque facteur identifi√© √† une cat√©gorie th√©matique appropri√©e en utilisant des embeddings s√©mantiques, et cr√©er des matrices de corr√©lation entre secteurs d'√©tude et domaines de politique.

## üèóÔ∏è Architecture

### Composants Principaux

- **`complete_pipeline.py`** : Pipeline complet orchestrant toutes les √©tapes
- **`db_to_csv.py`** : Script de transformation des donn√©es de la base vers CSV
- **`merge_policies_knn.py`** : Clustering s√©mantique des politiques avec FAISS
- **Base de donn√©es** : Table `policies_abstracts_all` contenant les politiques extraites
- **Mod√®les d'embeddings** : SentenceTransformers pour la classification s√©mantique
- **Taxonomie** : Syst√®me de classification des secteurs d'√©tude et domaines de politique

### Flux de Donn√©es Complet

```
Base de donn√©es ‚Üí Extraction ‚Üí Flattening ‚Üí Classification ‚Üí Clustering ‚Üí Matrices
     ‚Üì              ‚Üì           ‚Üì           ‚Üì           ‚Üì         ‚Üì
policies_abstracts_all ‚Üí JSON ‚Üí DataFrame ‚Üí Taxonomies ‚Üí Clusters ‚Üí CSV + Matrices
```

## üöÄ Installation

### Pr√©requis

- Python 3.8+
- Acc√®s √† la base de donn√©es PostgreSQL
- Mod√®les d'embeddings SentenceTransformers
- FAISS pour le clustering vectoriel

### D√©pendances

```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

```bash
pip install pandas numpy sentence-transformers scikit-learn faiss-cpu psycopg2-binary
```

### D√©pendances Principales

- `pandas` : Manipulation des donn√©es
- `sentence-transformers` : Mod√®les d'embeddings (all-MiniLM-L6-v2, paraphrase-multilingual-MiniLM-L12-v2)
- `scikit-learn` : Calculs de similarit√© cosinus et TF-IDF fallback
- `faiss-cpu` : Indexation vectorielle pour clustering
- `psycopg2-binary` : Connexion PostgreSQL

## üìä Structure des Donn√©es

### Donn√©es d'Entr√©e

La table `policies_abstracts_all` contient :
- `extracted_data` : JSON structur√© avec les politiques extraites
- `openalex_id` : Identifiant unique de l'article

### Format JSON des Donn√©es Extraites

```json
{
    "GEOGRAPHIC": "scope_geographique",
    "nom_politique": {
        "ACTOR": "institution_ou_personne",
        "POPULATION": "groupe_socio_demographique",
        "FACTOR": {
            "nom_facteur": {
                "CORRELATION": "type_correlation"
            }
        }
    }
}
```

### Donn√©es de Sortie

#### CSV Flattened (flattened_policies.csv)
- `policy` : Nom de la politique
- `actor` : Acteur responsable
- `population` : Population cible
- `factor` : Facteur d'impact
- `correlation` : Type de corr√©lation (increasing/decreasing)
- `related_studied_policy_area` : Domaine de politique associ√©
- `related_studied_sector` : Secteur d'√©tude associ√©
- `correlation_numeric` : Valeur num√©rique (-1, 0, 1)

#### Matrice de Corr√©lation (complete_policy_sector_matrix.csv)
Matrice pivot croisant les domaines de politique (lignes) avec les secteurs d'√©tude (colonnes), contenant les valeurs de corr√©lation moyennes.

## üîß Utilisation

### Pipeline Complet

```bash
python complete_pipeline.py
```

Le pipeline complet ex√©cute automatiquement :
1. Extraction des donn√©es de la base
2. Flattening des donn√©es JSON
3. Attribution des taxonomies
4. Transformation des corr√©lations
5. Cr√©ation de la matrice pivot
6. Sauvegarde des r√©sultats

### Utilisation Programm√©e

```python
from complete_pipeline import run_complete_pipeline

# Ex√©cuter le pipeline complet
result = run_complete_pipeline(limit=100, sim_threshold=0.75)
```

### Extraction et Transformation Manuelles

```python
from db_to_csv import (
    get_dataframe_with_filters, 
    flatten_extracted_data, 
    assign_factor_to_related_taxonomies, 
    assign_policy_to_related_taxonomies
)

# R√©cup√©rer les donn√©es avec filtres
df = get_dataframe_with_filters(limit=100)

# Transformer en format aplati
flattened_df = flatten_extracted_data(df)

# Appliquer la classification taxonomique
flattened_df['related_studied_policy_area'] = flattened_df['factor'].apply(assign_factor_to_related_taxonomies)
flattened_df['related_studied_sector'] = flattened_df['policy'].apply(assign_policy_to_related_taxonomies)
```

### Clustering S√©mantique

```python
from merge_policies_knn import merge_policies_semantic_medoid

# Clustering des politiques similaires
clustered_df = merge_policies_semantic_medoid(
    df,
    text_col="policy",
    batch_size=32,
    max_neighbors=10,
    sim_threshold=0.78
)
```

## üß† Classification S√©mantique

### Algorithme

1. **Encodage** : Conversion des cat√©gories de taxonomie et des facteurs en vecteurs
2. **Similarit√©** : Calcul de similarit√© cosinus entre facteurs et cat√©gories
3. **Classification** : Attribution de la cat√©gorie la plus proche s√©mantiquement

### Mod√®les Utilis√©s

- **Mod√®le principal** : `all-MiniLM-L6-v2` (rapide et efficace)
- **Mod√®le multilingue** : `paraphrase-multilingual-MiniLM-L12-v2` (optionnel)
- **Fallback TF-IDF** : En cas d'√©chec des mod√®les d'embeddings

### Taxonomies Support√©es

- **Secteurs d'√©tude** : agriculture, biodiversity, climate_action, cohesion, culture, economy, education_and_youth, energy, equality, finance_and_capital_markets, food, health, home_affairs, innovation_and_research, jobs, justice, reforms, social_rights, transport
- **Domaines de politique** : Bas√©s sur la taxonomie des th√®mes

## üîç Clustering S√©mantique

### Algorithme FAISS + Medoid

1. **Embedding** : Conversion des textes de politiques en vecteurs normalis√©s
2. **Indexation** : Construction d'un index FAISS pour recherche rapide
3. **k-NN** : Recherche des voisins les plus proches
4. **Clustering** : Groupement par composantes connexes
5. **Canonisation** : S√©lection du repr√©sentant m√©dian de chaque cluster

### Configuration

```python
class Config:
    text_col: str = "policy"
    model_name: str = "all-MiniLM-L6-v2"
    batch_size: int = 32
    max_neighbors: int = 10
    sim_threshold: float = 0.78
    normalize_text_flag: bool = True
```

## üìÅ Structure du Projet

```
policies_transformation_to_matrices/
‚îú‚îÄ‚îÄ README.md                           # Ce fichier
‚îú‚îÄ‚îÄ complete_pipeline.py               # Pipeline principal orchestrant tout
‚îú‚îÄ‚îÄ db_to_csv.py                      # Extraction et transformation des donn√©es
‚îú‚îÄ‚îÄ merge_policies_knn.py             # Clustering s√©mantique avec FAISS
‚îú‚îÄ‚îÄ test_merge_policies.py            # Tests du clustering
‚îú‚îÄ‚îÄ test_import.py                    # Tests d'import
‚îú‚îÄ‚îÄ complete_flattened_policies.csv   # Donn√©es aplaties avec taxonomies
‚îú‚îÄ‚îÄ complete_policy_sector_matrix.csv # Matrice de corr√©lation finale
‚îú‚îÄ‚îÄ policy_clusters.csv               # R√©sultats du clustering
‚îú‚îÄ‚îÄ flattened_policies.csv            # Exemple de sortie
‚îú‚îÄ‚îÄ policy_sector_correlation_matrix.csv # Matrice de corr√©lation
‚îî‚îÄ‚îÄ venv/                             # Environnement virtuel
```

## üîç Fonctionnalit√©s

### Extraction de Donn√©es
- Connexion s√©curis√©e √† la base de donn√©es PostgreSQL
- Requ√™tes SQL personnalisables avec filtres
- Gestion des erreurs et logging d√©taill√©
- Support des formats JSON vari√©s

### Transformation des Donn√©es
- Parsing automatique du JSON imbriqu√©
- Gestion des structures de donn√©es vari√©es
- Flattening intelligent des donn√©es hi√©rarchiques
- Normalisation des valeurs de corr√©lation

### Classification Taxonomique
- Attribution automatique des secteurs d'√©tude
- Attribution automatique des domaines de politique
- Gestion des cas limites et valeurs manquantes
- Traitement par batch pour optimiser la m√©moire

### Clustering S√©mantique
- Groupement automatique des politiques similaires
- S√©lection de repr√©sentants canoniques
- Optimisation m√©moire avec FAISS
- Fallback TF-IDF en cas d'√©chec

### Analyse et Visualisation
- Cr√©ation de matrices de corr√©lation
- Agr√©gation des donn√©es par secteur/domaine
- Export CSV structur√© pour analyse

## üìù Logging et Debug

Le syst√®me inclut un logging complet configur√© dans `complete_pipeline.py` :

```python
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
```

### Informations Logg√©es
- Progression des √©tapes du pipeline
- Nombre de politiques trait√©es
- Erreurs de parsing JSON
- R√©sultats de classification taxonomique
- Statistiques de clustering

## üö® Gestion d'Erreurs

### Types d'Erreurs G√©r√©es
- **Connexion DB** : Erreurs de connexion et requ√™tes
- **Parsing JSON** : Donn√©es malform√©es ou manquantes
- **Classification** : √âchecs d'encodage ou de similarit√©
- **Clustering** : Probl√®mes de m√©moire ou d'indexation
- **Fichiers** : Probl√®mes d'√©criture CSV

### Strat√©gies de R√©cup√©ration
- Continuation du traitement en cas d'erreur sur une ligne
- Fallback vers TF-IDF en cas d'√©chec des embeddings
- Logging d√©taill√© pour le debugging
- Valeurs par d√©faut pour les donn√©es manquantes
- Traitement par batch pour √©viter les probl√®mes de m√©moire

## üìà Performance

### Optimisations
- Encodage des cat√©gories de taxonomie une seule fois
- Traitement par batch des donn√©es
- Indexation FAISS pour clustering rapide
- Gestion m√©moire efficace avec pandas
- Mod√®les d'embeddings l√©gers (MiniLM)

### Limitations Actuelles
- Traitement s√©quentiel des politiques
- Chargement complet des donn√©es en m√©moire
- Pas de parall√©lisation des calculs de similarit√©

### M√©triques de Performance
- **Temps de traitement** : ~2-5 minutes pour 1000 politiques
- **Utilisation m√©moire** : ~2-4 GB selon la taille des donn√©es
- **Pr√©cision clustering** : 85-95% selon le seuil de similarit√©

## üîÆ √âvolutions Futures

### Am√©liorations Planifi√©es
- [ ] Traitement parall√®le des politiques
- [ ] Cache des embeddings de taxonomie
- [ ] Interface web pour la configuration
- [ ] Support de formats d'export multiples (JSON, Excel)
- [ ] M√©triques de qualit√© de classification
- [ ] Visualisation interactive des matrices

### Optimisations Techniques
- [ ] Streaming des donn√©es volumineuses
- [ ] Indexation vectorielle persistante
- [ ] Mod√®les d'embeddings plus performants
- [ ] Clustering incr√©mental
- [ ] API REST pour l'int√©gration

## üß™ Tests

### Tests Disponibles

```bash
# Test du clustering
python test_merge_policies.py

# Test d'import
python test_import.py
```

### Tests du Pipeline Complet

Le pipeline complet peut √™tre test√© avec diff√©rentes configurations :

```python
# Test avec peu de donn√©es
result = run_complete_pipeline(limit=10, sim_threshold=0.8)

# Test avec seuil de similarit√© √©lev√©
result = run_complete_pipeline(limit=50, sim_threshold=0.85)
```

## ü§ù Contribution

### D√©veloppement Local
1. Cloner le repository
2. Installer les d√©pendances : `pip install -r requirements.txt`
3. Configurer la connexion √† la base de donn√©es
4. Ex√©cuter les tests : `python test_merge_policies.py`

### Standards de Code
- Documentation des fonctions avec docstrings
- Gestion d'erreurs robuste avec try/catch
- Logging appropri√© √† chaque niveau
- Tests unitaires pour les composants critiques
- Configuration centralis√©e dans des classes

### Ajout de Nouvelles Fonctionnalit√©s
1. Cr√©er le script dans le dossier appropri√©
2. Ajouter les tests correspondants
3. Mettre √† jour ce README
4. V√©rifier la compatibilit√© avec le pipeline existant

## üìö R√©f√©rences

- [SentenceTransformers Documentation](https://www.sbert.net/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)
- [Scikit-learn Cosine Similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)
- [Pandas Documentation](https://pandas.pydata.org/)
- [PostgreSQL psycopg2](https://www.psycopg.org/)

## üìû Support et D√©pannage

### Probl√®mes Courants

1. **Erreur de m√©moire** : R√©duire `batch_size` et `max_neighbors`
2. **√âchec des embeddings** : Le syst√®me bascule automatiquement vers TF-IDF
3. **Connexion DB** : V√©rifier les param√®tres de connexion
4. **Performance lente** : Ajuster le seuil de similarit√©

### Logs et Debugging

```python
# Augmenter le niveau de log
logging.basicConfig(level=logging.DEBUG)

# V√©rifier les √©tapes du pipeline
logger.info("√âtape actuelle: ...")
```

### Contact

Pour toute question ou probl√®me :
1. V√©rifier les logs d'erreur d√©taill√©s
2. Consulter la documentation des d√©pendances
3. V√©rifier la configuration de la base de donn√©es
4. Ex√©cuter les tests de base
5. Contacter l'√©quipe de d√©veloppement

---

**Version** : 2.0.0  
**Maintenu par** : √âquipe D4G Sobri√©t√©  
**Statut** : Production - Pipeline complet fonctionnel 